{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8904a67d",
   "metadata": {},
   "source": [
    "### 베이지안 최적화 개요와 HyperOpt 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6596709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.7\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "\n",
    "print(hyperopt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f893afc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt==0.2.7 in c:\\users\\jeongbs1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\jeongbs1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from hyperopt==0.2.7) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\jeongbs1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from hyperopt==0.2.7) (1.14.1)\n",
      "Requirement already satisfied: six in c:\\users\\jeongbs1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from hyperopt==0.2.7) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\jeongbs1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from hyperopt==0.2.7) (3.3)\n",
      "Requirement already satisfied: future in c:\\users\\jeongbs1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from hyperopt==0.2.7) (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jeongbs1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from hyperopt==0.2.7) (4.66.5)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\jeongbs1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from hyperopt==0.2.7) (3.0.0)\n",
      "Requirement already satisfied: py4j in c:\\users\\jeongbs1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from hyperopt==0.2.7) (0.10.9.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\jeongbs1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->hyperopt==0.2.7) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt==0.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e4fdabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# -10 ~ 10까지 1간격을 가지는 입력 변수 x 집합값과 -15 ~ 15까지 1간격을 가지는 입력 변수  y 집합값 설정.\n",
    "search_space = {'x': hp.quniform('x', -10, 10, 1),  'y': hp.quniform('y', -15, 15, 1) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4dcf5c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# 목적 함수를 생성. 입력 변수값과 입력 변수 검색 범위를 가지는 딕셔너리를 인자로 받고, 특정 값을 반환\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 - 20*y\n",
    "    \n",
    "    return retval # return {'loss': retval, 'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8042337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<?, ?trial/s, best loss: -224.0]\n",
      "best: {'x': -4.0, 'y': 12.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "import numpy as np\n",
    "\n",
    "# 입력 결괏값을 저장한 Trials 객체값 생성.\n",
    "trial_val = Trials()\n",
    "\n",
    "# 목적 함수의 최솟값을 반환하는 최적 입력 변숫값을 5번의 입력값 시도(max_evals=5)로 찾아냄.\n",
    "best_01 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=5\n",
    "               , trials=trial_val, rstate=np.random.default_rng(seed=0)\n",
    "              )\n",
    "print('best:', best_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bbbd861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 1463.21trial/s, best loss: -296.0]\n",
      "best: {'x': 2.0, 'y': 15.0}\n"
     ]
    }
   ],
   "source": [
    "trial_val = Trials()\n",
    "\n",
    "# max_evals를 20회로 늘려서 재테스트\n",
    "best_02 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=20\n",
    "               , trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "print('best:', best_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22cd2e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.base.Trials at 0x23bd041c590>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e06c5",
   "metadata": {},
   "source": [
    "* HyperOpt 수행 시 적용된 입력 값들과 목적 함수 반환값 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6624c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'loss': -64.0, 'status': 'ok'}, {'loss': -184.0, 'status': 'ok'}, {'loss': 56.0, 'status': 'ok'}, {'loss': -224.0, 'status': 'ok'}, {'loss': 61.0, 'status': 'ok'}, {'loss': -296.0, 'status': 'ok'}, {'loss': -40.0, 'status': 'ok'}, {'loss': 281.0, 'status': 'ok'}, {'loss': 64.0, 'status': 'ok'}, {'loss': 100.0, 'status': 'ok'}, {'loss': 60.0, 'status': 'ok'}, {'loss': -39.0, 'status': 'ok'}, {'loss': 1.0, 'status': 'ok'}, {'loss': -164.0, 'status': 'ok'}, {'loss': 21.0, 'status': 'ok'}, {'loss': -56.0, 'status': 'ok'}, {'loss': 284.0, 'status': 'ok'}, {'loss': 176.0, 'status': 'ok'}, {'loss': -171.0, 'status': 'ok'}, {'loss': 0.0, 'status': 'ok'}]\n"
     ]
    }
   ],
   "source": [
    "# fmin( )에 인자로 들어가는 Trials 객체의 result 속성에 파이썬 리스트로 목적 함수 반환값들이 저장됨\n",
    "# 리스트 내부의 개별 원소는 {'loss':함수 반환값, 'status':반환 상태값} 와 같은 딕셔너리임. \n",
    "print(trial_val.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7cafa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [-6.0, -4.0, 4.0, -4.0, 9.0, 2.0, 10.0, -9.0, -8.0, -0.0, -0.0, 1.0, 9.0, 6.0, 9.0, 2.0, -2.0, -4.0, 7.0, -0.0], 'y': [5.0, 10.0, -2.0, 12.0, 1.0, 15.0, 7.0, -10.0, 0.0, -5.0, -3.0, 2.0, 4.0, 10.0, 3.0, 3.0, -14.0, -8.0, 11.0, -0.0]}\n"
     ]
    }
   ],
   "source": [
    "# Trials 객체의 vals 속성에 {'입력변수명':개별 수행 시마다 입력된 값 리스트} 형태로 저장됨.\n",
    "print(trial_val.vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6272c51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x     y  losses\n",
       "0   -6.0   5.0   -64.0\n",
       "1   -4.0  10.0  -184.0\n",
       "2    4.0  -2.0    56.0\n",
       "3   -4.0  12.0  -224.0\n",
       "4    9.0   1.0    61.0\n",
       "5    2.0  15.0  -296.0\n",
       "6   10.0   7.0   -40.0\n",
       "7   -9.0 -10.0   281.0\n",
       "8   -8.0   0.0    64.0\n",
       "9   -0.0  -5.0   100.0\n",
       "10  -0.0  -3.0    60.0\n",
       "11   1.0   2.0   -39.0\n",
       "12   9.0   4.0     1.0\n",
       "13   6.0  10.0  -164.0\n",
       "14   9.0   3.0    21.0\n",
       "15   2.0   3.0   -56.0\n",
       "16  -2.0 -14.0   284.0\n",
       "17  -4.0  -8.0   176.0\n",
       "18   7.0  11.0  -171.0\n",
       "19  -0.0  -0.0     0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# results에서 loss 키값에 해당하는 밸류들을 추출하여 list로 생성. \n",
    "losses = [loss_dict['loss'] for loss_dict in trial_val.results]\n",
    "\n",
    "# DataFrame으로 생성. \n",
    "result_df = pd.DataFrame({'x': trial_val.vals['x'],\n",
    "                         'y': trial_val.vals['y'],\n",
    "                          'losses': losses\n",
    "                         }\n",
    "                        )\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c74b02",
   "metadata": {},
   "source": [
    "### HyperOpt를 XGBoost 하이퍼 파라미터 튜닝에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "577be02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "cancer_df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "cancer_df['target']= dataset.target\n",
    "X_features = cancer_df.iloc[:, :-1]\n",
    "y_label = cancer_df.iloc[:, -1]\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_label,\n",
    "                                         test_size=0.2, random_state=156 )\n",
    "\n",
    "# 학습 데이터를 다시 학습과 검증 데이터로 분리 \n",
    "X_tr, X_val, y_tr, y_val= train_test_split(X_train, y_train,\n",
    "                                         test_size=0.1, random_state=156 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1cc93692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': <hyperopt.pyll.base.Apply object at 0x0000023BD3BEA2D0>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x0000023BD3BF3740>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x0000023BD3BF0350>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x0000023BD3BF1AC0>}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# max_depth는 5에서 20까지 1간격으로, min_child_weight는 1에서 2까지 1간격으로\n",
    "# colsample_bytree는 0.5에서 1사이, learning_rate는 0.01에서 0.2사이 정규 분포된 값으로 검색. \n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1),\n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1)\n",
    "               }\n",
    "print(xgb_search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af2b0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# fmin()에서 입력된 search_space값으로 입력된 모든 값은 실수형임. \n",
    "# XGBClassifier의 정수형 하이퍼 파라미터는 정수형 변환을 해줘야 함. \n",
    "# 정확도는 높은 수록 더 좋은 수치임. -1* 정확도를 곱해서 큰 정확도 값일 수록 최소가 되도록 변환\n",
    "def objective_func(search_space):\n",
    "    # 수행 시간 절약을 위해 n_estimators는 100으로 축소\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            learning_rate=search_space['learning_rate'],\n",
    "                            colsample_bytree=search_space['colsample_bytree'], \n",
    "                            eval_metric='logloss')\n",
    "    \n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3)\n",
    "        \n",
    "    # accuracy는 cv=3 개수만큼의 정확도 결과를 가지므로 이를 평균해서 반환하되 -1을 곱해줌. \n",
    "    return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "767592d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1231, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1245, in <lambda>\n",
      "    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\data.py\", line 707, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\data.py\", line 297, in _from_pandas_df\n",
      "    data, feature_names, feature_types = _transform_pandas_df(\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\data.py\", line 250, in _transform_pandas_df\n",
      "    elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "                                   ^^^^^^^^^^^^^\n",
      "AttributeError: module 'pandas' has no attribute 'Int64Index'\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n           ^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1231, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n                    ^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1245, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n           ^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n                                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\data.py\", line 707, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\data.py\", line 297, in _from_pandas_df\n    data, feature_names, feature_types = _transform_pandas_df(\n                                         ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\data.py\", line 250, in _transform_pandas_df\n    elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n                                   ^^^^^^^^^^^^^\nAttributeError: module 'pandas' has no attribute 'Int64Index'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhyperopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin, tpe, Trials\n\u001b[0;32m      3\u001b[0m trial_val \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[1;32m----> 4\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_search_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 최대 반복 횟수를 지정합니다.\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_rng\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest:\u001b[39m\u001b[38;5;124m'\u001b[39m, best)\n",
      "File \u001b[1;32mc:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mc:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[68], line 16\u001b[0m, in \u001b[0;36mobjective_func\u001b[1;34m(search_space)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective_func\u001b[39m(search_space):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# 수행 시간 절약을 위해 n_estimators는 100으로 축소\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     xgb_clf \u001b[38;5;241m=\u001b[39m XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(search_space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     11\u001b[0m                             min_child_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(search_space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_child_weight\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     12\u001b[0m                             learning_rate\u001b[38;5;241m=\u001b[39msearch_space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     13\u001b[0m                             colsample_bytree\u001b[38;5;241m=\u001b[39msearch_space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     14\u001b[0m                             eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# accuracy는 cv=3 개수만큼의 정확도 결과를 가지므로 이를 평균해서 반환하되 -1을 곱해줌. \u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(accuracy), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: STATUS_OK}\n",
      "File \u001b[1;32mc:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    425\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    441\u001b[0m )\n\u001b[1;32m--> 443\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n           ^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1231, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n                    ^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1245, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n           ^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n                                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\data.py\", line 707, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\data.py\", line 297, in _from_pandas_df\n    data, feature_names, feature_types = _transform_pandas_df(\n                                         ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jeongbs1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\data.py\", line 250, in _transform_pandas_df\n    elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n                                   ^^^^^^^^^^^^^\nAttributeError: module 'pandas' has no attribute 'Int64Index'\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn=objective_func,\n",
    "            space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trial_val, rstate=np.random.default_rng(seed=9))\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee280368",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree:\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, learning_rate:\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m, max_depth:\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m, min_child_weight:\u001b[39m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m----> 2\u001b[0m                         \u001b[38;5;28mround\u001b[39m(\u001b[43mbest\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m5\u001b[39m), \u001b[38;5;28mround\u001b[39m(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m      3\u001b[0m                         \u001b[38;5;28mint\u001b[39m(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_child_weight\u001b[39m\u001b[38;5;124m'\u001b[39m])))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best' is not defined"
     ]
    }
   ],
   "source": [
    "print('colsample_bytree:{0}, learning_rate:{1}, max_depth:{2}, min_child_weight:{3}'.format(\n",
    "                        round(best['colsample_bytree'], 5), round(best['learning_rate'], 5),\n",
    "                        int(best['max_depth']), int(best['min_child_weight'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "711de322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6aabd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.58942\tvalidation_1-logloss:0.62048\n",
      "[1]\tvalidation_0-logloss:0.50801\tvalidation_1-logloss:0.55913\n",
      "[2]\tvalidation_0-logloss:0.44160\tvalidation_1-logloss:0.50928\n",
      "[3]\tvalidation_0-logloss:0.38734\tvalidation_1-logloss:0.46815\n",
      "[4]\tvalidation_0-logloss:0.34224\tvalidation_1-logloss:0.43913\n",
      "[5]\tvalidation_0-logloss:0.30425\tvalidation_1-logloss:0.41570\n",
      "[6]\tvalidation_0-logloss:0.27178\tvalidation_1-logloss:0.38953\n",
      "[7]\tvalidation_0-logloss:0.24503\tvalidation_1-logloss:0.37317\n",
      "[8]\tvalidation_0-logloss:0.22050\tvalidation_1-logloss:0.35628\n",
      "[9]\tvalidation_0-logloss:0.19873\tvalidation_1-logloss:0.33798\n",
      "[10]\tvalidation_0-logloss:0.17945\tvalidation_1-logloss:0.32463\n",
      "[11]\tvalidation_0-logloss:0.16354\tvalidation_1-logloss:0.31384\n",
      "[12]\tvalidation_0-logloss:0.15032\tvalidation_1-logloss:0.30607\n",
      "[13]\tvalidation_0-logloss:0.13813\tvalidation_1-logloss:0.30143\n",
      "[14]\tvalidation_0-logloss:0.12798\tvalidation_1-logloss:0.29513\n",
      "[15]\tvalidation_0-logloss:0.11926\tvalidation_1-logloss:0.28891\n",
      "[16]\tvalidation_0-logloss:0.11111\tvalidation_1-logloss:0.28290\n",
      "[17]\tvalidation_0-logloss:0.10351\tvalidation_1-logloss:0.27835\n",
      "[18]\tvalidation_0-logloss:0.09474\tvalidation_1-logloss:0.27295\n",
      "[19]\tvalidation_0-logloss:0.08922\tvalidation_1-logloss:0.27215\n",
      "[20]\tvalidation_0-logloss:0.08406\tvalidation_1-logloss:0.27168\n",
      "[21]\tvalidation_0-logloss:0.07892\tvalidation_1-logloss:0.27093\n",
      "[22]\tvalidation_0-logloss:0.07355\tvalidation_1-logloss:0.26561\n",
      "[23]\tvalidation_0-logloss:0.06976\tvalidation_1-logloss:0.26670\n",
      "[24]\tvalidation_0-logloss:0.06569\tvalidation_1-logloss:0.26871\n",
      "[25]\tvalidation_0-logloss:0.06220\tvalidation_1-logloss:0.26484\n",
      "[26]\tvalidation_0-logloss:0.05946\tvalidation_1-logloss:0.26604\n",
      "[27]\tvalidation_0-logloss:0.05688\tvalidation_1-logloss:0.26836\n",
      "[28]\tvalidation_0-logloss:0.05457\tvalidation_1-logloss:0.26746\n",
      "[29]\tvalidation_0-logloss:0.05161\tvalidation_1-logloss:0.26410\n",
      "[30]\tvalidation_0-logloss:0.04900\tvalidation_1-logloss:0.26314\n",
      "[31]\tvalidation_0-logloss:0.04658\tvalidation_1-logloss:0.26210\n",
      "[32]\tvalidation_0-logloss:0.04442\tvalidation_1-logloss:0.25918\n",
      "[33]\tvalidation_0-logloss:0.04293\tvalidation_1-logloss:0.25575\n",
      "[34]\tvalidation_0-logloss:0.04149\tvalidation_1-logloss:0.25681\n",
      "[35]\tvalidation_0-logloss:0.03991\tvalidation_1-logloss:0.25727\n",
      "[36]\tvalidation_0-logloss:0.03849\tvalidation_1-logloss:0.25710\n",
      "[37]\tvalidation_0-logloss:0.03702\tvalidation_1-logloss:0.25274\n",
      "[38]\tvalidation_0-logloss:0.03552\tvalidation_1-logloss:0.25427\n",
      "[39]\tvalidation_0-logloss:0.03441\tvalidation_1-logloss:0.25366\n",
      "[40]\tvalidation_0-logloss:0.03335\tvalidation_1-logloss:0.25410\n",
      "[41]\tvalidation_0-logloss:0.03259\tvalidation_1-logloss:0.25415\n",
      "[42]\tvalidation_0-logloss:0.03172\tvalidation_1-logloss:0.25421\n",
      "[43]\tvalidation_0-logloss:0.03110\tvalidation_1-logloss:0.25265\n",
      "[44]\tvalidation_0-logloss:0.03025\tvalidation_1-logloss:0.24974\n",
      "[45]\tvalidation_0-logloss:0.02961\tvalidation_1-logloss:0.25033\n",
      "[46]\tvalidation_0-logloss:0.02904\tvalidation_1-logloss:0.24858\n",
      "[47]\tvalidation_0-logloss:0.02849\tvalidation_1-logloss:0.25082\n",
      "[48]\tvalidation_0-logloss:0.02802\tvalidation_1-logloss:0.24968\n",
      "[49]\tvalidation_0-logloss:0.02741\tvalidation_1-logloss:0.24913\n",
      "[50]\tvalidation_0-logloss:0.02689\tvalidation_1-logloss:0.24924\n",
      "[51]\tvalidation_0-logloss:0.02644\tvalidation_1-logloss:0.24483\n",
      "[52]\tvalidation_0-logloss:0.02593\tvalidation_1-logloss:0.24508\n",
      "[53]\tvalidation_0-logloss:0.02534\tvalidation_1-logloss:0.24153\n",
      "[54]\tvalidation_0-logloss:0.02500\tvalidation_1-logloss:0.23781\n",
      "[55]\tvalidation_0-logloss:0.02458\tvalidation_1-logloss:0.23909\n",
      "[56]\tvalidation_0-logloss:0.02422\tvalidation_1-logloss:0.23809\n",
      "[57]\tvalidation_0-logloss:0.02380\tvalidation_1-logloss:0.23843\n",
      "[58]\tvalidation_0-logloss:0.02347\tvalidation_1-logloss:0.23802\n",
      "[59]\tvalidation_0-logloss:0.02310\tvalidation_1-logloss:0.23837\n",
      "[60]\tvalidation_0-logloss:0.02275\tvalidation_1-logloss:0.23923\n",
      "[61]\tvalidation_0-logloss:0.02257\tvalidation_1-logloss:0.23813\n",
      "[62]\tvalidation_0-logloss:0.02242\tvalidation_1-logloss:0.23983\n",
      "[63]\tvalidation_0-logloss:0.02227\tvalidation_1-logloss:0.23883\n",
      "[64]\tvalidation_0-logloss:0.02186\tvalidation_1-logloss:0.23589\n",
      "[65]\tvalidation_0-logloss:0.02162\tvalidation_1-logloss:0.23630\n",
      "[66]\tvalidation_0-logloss:0.02149\tvalidation_1-logloss:0.23795\n",
      "[67]\tvalidation_0-logloss:0.02136\tvalidation_1-logloss:0.23704\n",
      "[68]\tvalidation_0-logloss:0.02123\tvalidation_1-logloss:0.23670\n",
      "[69]\tvalidation_0-logloss:0.02097\tvalidation_1-logloss:0.23745\n",
      "[70]\tvalidation_0-logloss:0.02087\tvalidation_1-logloss:0.23739\n",
      "[71]\tvalidation_0-logloss:0.02073\tvalidation_1-logloss:0.23908\n",
      "[72]\tvalidation_0-logloss:0.02062\tvalidation_1-logloss:0.24064\n",
      "[73]\tvalidation_0-logloss:0.02050\tvalidation_1-logloss:0.23973\n",
      "[74]\tvalidation_0-logloss:0.02039\tvalidation_1-logloss:0.23972\n",
      "[75]\tvalidation_0-logloss:0.02029\tvalidation_1-logloss:0.23927\n",
      "[76]\tvalidation_0-logloss:0.02019\tvalidation_1-logloss:0.24081\n",
      "[77]\tvalidation_0-logloss:0.02008\tvalidation_1-logloss:0.24054\n",
      "[78]\tvalidation_0-logloss:0.01999\tvalidation_1-logloss:0.23844\n",
      "[79]\tvalidation_0-logloss:0.01989\tvalidation_1-logloss:0.23762\n",
      "[80]\tvalidation_0-logloss:0.01979\tvalidation_1-logloss:0.23914\n",
      "[81]\tvalidation_0-logloss:0.01969\tvalidation_1-logloss:0.23907\n",
      "[82]\tvalidation_0-logloss:0.01960\tvalidation_1-logloss:0.23830\n",
      "[83]\tvalidation_0-logloss:0.01952\tvalidation_1-logloss:0.23866\n",
      "[84]\tvalidation_0-logloss:0.01943\tvalidation_1-logloss:0.23841\n",
      "[85]\tvalidation_0-logloss:0.01933\tvalidation_1-logloss:0.23992\n",
      "[86]\tvalidation_0-logloss:0.01925\tvalidation_1-logloss:0.23917\n",
      "[87]\tvalidation_0-logloss:0.01916\tvalidation_1-logloss:0.24061\n",
      "[88]\tvalidation_0-logloss:0.01908\tvalidation_1-logloss:0.23862\n",
      "[89]\tvalidation_0-logloss:0.01900\tvalidation_1-logloss:0.23858\n",
      "[90]\tvalidation_0-logloss:0.01892\tvalidation_1-logloss:0.23843\n",
      "[91]\tvalidation_0-logloss:0.01884\tvalidation_1-logloss:0.23837\n",
      "[92]\tvalidation_0-logloss:0.01876\tvalidation_1-logloss:0.23978\n",
      "[93]\tvalidation_0-logloss:0.01868\tvalidation_1-logloss:0.23787\n",
      "[94]\tvalidation_0-logloss:0.01860\tvalidation_1-logloss:0.23862\n",
      "[95]\tvalidation_0-logloss:0.01853\tvalidation_1-logloss:0.23770\n",
      "[96]\tvalidation_0-logloss:0.01845\tvalidation_1-logloss:0.23767\n",
      "[97]\tvalidation_0-logloss:0.01838\tvalidation_1-logloss:0.23840\n",
      "[98]\tvalidation_0-logloss:0.01831\tvalidation_1-logloss:0.23817\n",
      "[99]\tvalidation_0-logloss:0.01824\tvalidation_1-logloss:0.23950\n",
      "[100]\tvalidation_0-logloss:0.01817\tvalidation_1-logloss:0.23945\n",
      "[101]\tvalidation_0-logloss:0.01809\tvalidation_1-logloss:0.23848\n",
      "[102]\tvalidation_0-logloss:0.01802\tvalidation_1-logloss:0.23668\n",
      "[103]\tvalidation_0-logloss:0.01795\tvalidation_1-logloss:0.23704\n",
      "[104]\tvalidation_0-logloss:0.01789\tvalidation_1-logloss:0.23536\n",
      "[105]\tvalidation_0-logloss:0.01781\tvalidation_1-logloss:0.23465\n",
      "[106]\tvalidation_0-logloss:0.01774\tvalidation_1-logloss:0.23536\n",
      "[107]\tvalidation_0-logloss:0.01768\tvalidation_1-logloss:0.23514\n",
      "[108]\tvalidation_0-logloss:0.01762\tvalidation_1-logloss:0.23447\n",
      "[109]\tvalidation_0-logloss:0.01756\tvalidation_1-logloss:0.23281\n",
      "[110]\tvalidation_0-logloss:0.01749\tvalidation_1-logloss:0.23447\n",
      "[111]\tvalidation_0-logloss:0.01743\tvalidation_1-logloss:0.23443\n",
      "[112]\tvalidation_0-logloss:0.01737\tvalidation_1-logloss:0.23512\n",
      "[113]\tvalidation_0-logloss:0.01731\tvalidation_1-logloss:0.23465\n",
      "[114]\tvalidation_0-logloss:0.01725\tvalidation_1-logloss:0.23379\n",
      "[115]\tvalidation_0-logloss:0.01719\tvalidation_1-logloss:0.23446\n",
      "[116]\tvalidation_0-logloss:0.01714\tvalidation_1-logloss:0.23443\n",
      "[117]\tvalidation_0-logloss:0.01708\tvalidation_1-logloss:0.23360\n",
      "[118]\tvalidation_0-logloss:0.01702\tvalidation_1-logloss:0.23195\n",
      "[119]\tvalidation_0-logloss:0.01696\tvalidation_1-logloss:0.23262\n",
      "[120]\tvalidation_0-logloss:0.01691\tvalidation_1-logloss:0.23104\n",
      "[121]\tvalidation_0-logloss:0.01685\tvalidation_1-logloss:0.23145\n",
      "[122]\tvalidation_0-logloss:0.01680\tvalidation_1-logloss:0.23143\n",
      "[123]\tvalidation_0-logloss:0.01675\tvalidation_1-logloss:0.23131\n",
      "[124]\tvalidation_0-logloss:0.01670\tvalidation_1-logloss:0.23119\n",
      "[125]\tvalidation_0-logloss:0.01664\tvalidation_1-logloss:0.22965\n",
      "[126]\tvalidation_0-logloss:0.01659\tvalidation_1-logloss:0.23120\n",
      "[127]\tvalidation_0-logloss:0.01654\tvalidation_1-logloss:0.23119\n",
      "[128]\tvalidation_0-logloss:0.01649\tvalidation_1-logloss:0.23110\n",
      "[129]\tvalidation_0-logloss:0.01644\tvalidation_1-logloss:0.22957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130]\tvalidation_0-logloss:0.01639\tvalidation_1-logloss:0.22934\n",
      "[131]\tvalidation_0-logloss:0.01634\tvalidation_1-logloss:0.22987\n",
      "[132]\tvalidation_0-logloss:0.01629\tvalidation_1-logloss:0.22927\n",
      "[133]\tvalidation_0-logloss:0.01624\tvalidation_1-logloss:0.23076\n",
      "[134]\tvalidation_0-logloss:0.01620\tvalidation_1-logloss:0.23030\n",
      "[135]\tvalidation_0-logloss:0.01615\tvalidation_1-logloss:0.22891\n",
      "[136]\tvalidation_0-logloss:0.01610\tvalidation_1-logloss:0.22883\n",
      "[137]\tvalidation_0-logloss:0.01606\tvalidation_1-logloss:0.22882\n",
      "[138]\tvalidation_0-logloss:0.01602\tvalidation_1-logloss:0.22876\n",
      "[139]\tvalidation_0-logloss:0.01597\tvalidation_1-logloss:0.22734\n",
      "[140]\tvalidation_0-logloss:0.01592\tvalidation_1-logloss:0.22881\n",
      "[141]\tvalidation_0-logloss:0.01588\tvalidation_1-logloss:0.22935\n",
      "[142]\tvalidation_0-logloss:0.01583\tvalidation_1-logloss:0.22880\n",
      "[143]\tvalidation_0-logloss:0.01579\tvalidation_1-logloss:0.22856\n",
      "[144]\tvalidation_0-logloss:0.01575\tvalidation_1-logloss:0.22725\n",
      "[145]\tvalidation_0-logloss:0.01571\tvalidation_1-logloss:0.22739\n",
      "[146]\tvalidation_0-logloss:0.01567\tvalidation_1-logloss:0.22724\n",
      "[147]\tvalidation_0-logloss:0.01562\tvalidation_1-logloss:0.22777\n",
      "[148]\tvalidation_0-logloss:0.01558\tvalidation_1-logloss:0.22726\n",
      "[149]\tvalidation_0-logloss:0.01555\tvalidation_1-logloss:0.22721\n",
      "[150]\tvalidation_0-logloss:0.01551\tvalidation_1-logloss:0.22697\n",
      "[151]\tvalidation_0-logloss:0.01546\tvalidation_1-logloss:0.22645\n",
      "[152]\tvalidation_0-logloss:0.01543\tvalidation_1-logloss:0.22782\n",
      "[153]\tvalidation_0-logloss:0.01539\tvalidation_1-logloss:0.22790\n",
      "[154]\tvalidation_0-logloss:0.01535\tvalidation_1-logloss:0.22665\n",
      "[155]\tvalidation_0-logloss:0.01531\tvalidation_1-logloss:0.22680\n",
      "[156]\tvalidation_0-logloss:0.01528\tvalidation_1-logloss:0.22732\n",
      "[157]\tvalidation_0-logloss:0.01524\tvalidation_1-logloss:0.22709\n",
      "[158]\tvalidation_0-logloss:0.01520\tvalidation_1-logloss:0.22659\n",
      "[159]\tvalidation_0-logloss:0.01516\tvalidation_1-logloss:0.22616\n",
      "[160]\tvalidation_0-logloss:0.01513\tvalidation_1-logloss:0.22631\n",
      "[161]\tvalidation_0-logloss:0.01509\tvalidation_1-logloss:0.22510\n",
      "[162]\tvalidation_0-logloss:0.01506\tvalidation_1-logloss:0.22562\n",
      "[163]\tvalidation_0-logloss:0.01502\tvalidation_1-logloss:0.22539\n",
      "[164]\tvalidation_0-logloss:0.01499\tvalidation_1-logloss:0.22671\n",
      "[165]\tvalidation_0-logloss:0.01495\tvalidation_1-logloss:0.22625\n",
      "[166]\tvalidation_0-logloss:0.01492\tvalidation_1-logloss:0.22585\n",
      "[167]\tvalidation_0-logloss:0.01489\tvalidation_1-logloss:0.22583\n",
      "[168]\tvalidation_0-logloss:0.01485\tvalidation_1-logloss:0.22562\n",
      "[169]\tvalidation_0-logloss:0.01482\tvalidation_1-logloss:0.22520\n",
      "[170]\tvalidation_0-logloss:0.01479\tvalidation_1-logloss:0.22570\n",
      "[171]\tvalidation_0-logloss:0.01476\tvalidation_1-logloss:0.22587\n",
      "[172]\tvalidation_0-logloss:0.01472\tvalidation_1-logloss:0.22466\n",
      "[173]\tvalidation_0-logloss:0.01469\tvalidation_1-logloss:0.22592\n",
      "[174]\tvalidation_0-logloss:0.01466\tvalidation_1-logloss:0.22599\n",
      "[175]\tvalidation_0-logloss:0.01463\tvalidation_1-logloss:0.22556\n",
      "[176]\tvalidation_0-logloss:0.01460\tvalidation_1-logloss:0.22535\n",
      "[177]\tvalidation_0-logloss:0.01457\tvalidation_1-logloss:0.22655\n",
      "[178]\tvalidation_0-logloss:0.01454\tvalidation_1-logloss:0.22674\n",
      "[179]\tvalidation_0-logloss:0.01451\tvalidation_1-logloss:0.22565\n",
      "[180]\tvalidation_0-logloss:0.01448\tvalidation_1-logloss:0.22565\n",
      "[181]\tvalidation_0-logloss:0.01445\tvalidation_1-logloss:0.22526\n",
      "[182]\tvalidation_0-logloss:0.01442\tvalidation_1-logloss:0.22545\n",
      "[183]\tvalidation_0-logloss:0.01439\tvalidation_1-logloss:0.22504\n",
      "[184]\tvalidation_0-logloss:0.01436\tvalidation_1-logloss:0.22554\n",
      "[185]\tvalidation_0-logloss:0.01433\tvalidation_1-logloss:0.22533\n",
      "[186]\tvalidation_0-logloss:0.01431\tvalidation_1-logloss:0.22426\n",
      "[187]\tvalidation_0-logloss:0.01428\tvalidation_1-logloss:0.22545\n",
      "[188]\tvalidation_0-logloss:0.01425\tvalidation_1-logloss:0.22563\n",
      "[189]\tvalidation_0-logloss:0.01422\tvalidation_1-logloss:0.22525\n",
      "[190]\tvalidation_0-logloss:0.01419\tvalidation_1-logloss:0.22504\n",
      "[191]\tvalidation_0-logloss:0.01417\tvalidation_1-logloss:0.22523\n",
      "[192]\tvalidation_0-logloss:0.01414\tvalidation_1-logloss:0.22529\n",
      "[193]\tvalidation_0-logloss:0.01411\tvalidation_1-logloss:0.22492\n",
      "[194]\tvalidation_0-logloss:0.01409\tvalidation_1-logloss:0.22472\n",
      "[195]\tvalidation_0-logloss:0.01406\tvalidation_1-logloss:0.22589\n",
      "[196]\tvalidation_0-logloss:0.01403\tvalidation_1-logloss:0.22595\n",
      "[197]\tvalidation_0-logloss:0.01401\tvalidation_1-logloss:0.22646\n",
      "[198]\tvalidation_0-logloss:0.01399\tvalidation_1-logloss:0.22665\n",
      "[199]\tvalidation_0-logloss:0.01396\tvalidation_1-logloss:0.22628\n",
      "[200]\tvalidation_0-logloss:0.01393\tvalidation_1-logloss:0.22609\n",
      "[201]\tvalidation_0-logloss:0.01391\tvalidation_1-logloss:0.22572\n",
      "[202]\tvalidation_0-logloss:0.01388\tvalidation_1-logloss:0.22536\n",
      "[203]\tvalidation_0-logloss:0.01386\tvalidation_1-logloss:0.22586\n",
      "[204]\tvalidation_0-logloss:0.01384\tvalidation_1-logloss:0.22568\n",
      "[205]\tvalidation_0-logloss:0.01381\tvalidation_1-logloss:0.22678\n",
      "[206]\tvalidation_0-logloss:0.01379\tvalidation_1-logloss:0.22642\n",
      "[207]\tvalidation_0-logloss:0.01377\tvalidation_1-logloss:0.22690\n",
      "[208]\tvalidation_0-logloss:0.01375\tvalidation_1-logloss:0.22710\n",
      "[209]\tvalidation_0-logloss:0.01373\tvalidation_1-logloss:0.22676\n",
      "[210]\tvalidation_0-logloss:0.01371\tvalidation_1-logloss:0.22643\n",
      "[211]\tvalidation_0-logloss:0.01368\tvalidation_1-logloss:0.22624\n",
      "[212]\tvalidation_0-logloss:0.01366\tvalidation_1-logloss:0.22727\n",
      "[213]\tvalidation_0-logloss:0.01364\tvalidation_1-logloss:0.22693\n",
      "[214]\tvalidation_0-logloss:0.01362\tvalidation_1-logloss:0.22675\n",
      "[215]\tvalidation_0-logloss:0.01360\tvalidation_1-logloss:0.22644\n",
      "[216]\tvalidation_0-logloss:0.01357\tvalidation_1-logloss:0.22665\n",
      "[217]\tvalidation_0-logloss:0.01355\tvalidation_1-logloss:0.22685\n",
      "[218]\tvalidation_0-logloss:0.01353\tvalidation_1-logloss:0.22653\n",
      "[219]\tvalidation_0-logloss:0.01351\tvalidation_1-logloss:0.22622\n",
      "[220]\tvalidation_0-logloss:0.01350\tvalidation_1-logloss:0.22642\n",
      "[221]\tvalidation_0-logloss:0.01348\tvalidation_1-logloss:0.22612\n",
      "[222]\tvalidation_0-logloss:0.01346\tvalidation_1-logloss:0.22594\n",
      "[223]\tvalidation_0-logloss:0.01344\tvalidation_1-logloss:0.22641\n",
      "[224]\tvalidation_0-logloss:0.01342\tvalidation_1-logloss:0.22623\n",
      "[225]\tvalidation_0-logloss:0.01340\tvalidation_1-logloss:0.22668\n",
      "[226]\tvalidation_0-logloss:0.01338\tvalidation_1-logloss:0.22766\n",
      "[227]\tvalidation_0-logloss:0.01336\tvalidation_1-logloss:0.22736\n",
      "[228]\tvalidation_0-logloss:0.01334\tvalidation_1-logloss:0.22706\n",
      "[229]\tvalidation_0-logloss:0.01333\tvalidation_1-logloss:0.22727\n",
      "[230]\tvalidation_0-logloss:0.01331\tvalidation_1-logloss:0.22709\n",
      "[231]\tvalidation_0-logloss:0.01329\tvalidation_1-logloss:0.22694\n",
      "[232]\tvalidation_0-logloss:0.01327\tvalidation_1-logloss:0.22706\n",
      "[233]\tvalidation_0-logloss:0.01325\tvalidation_1-logloss:0.22676\n",
      "[234]\tvalidation_0-logloss:0.01324\tvalidation_1-logloss:0.22773\n",
      "[235]\tvalidation_0-logloss:0.01322\tvalidation_1-logloss:0.22743\n",
      "오차 행렬\n",
      "[[35  2]\n",
      " [ 2 75]]\n",
      "정확도: 0.9649, 정밀도: 0.9740, 재현율: 0.9740,    F1: 0.9740, AUC:0.9944\n"
     ]
    }
   ],
   "source": [
    "xgb_wrapper = XGBClassifier(n_estimators=400, learning_rate=round(best['learning_rate'], 5), \n",
    "                            max_depth=int(best['max_depth']), min_child_weight=int(best['min_child_weight']),\n",
    "                            colsample_bytree=round(best['colsample_bytree'], 5)\n",
    "                           )\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "xgb_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50, eval_metric='logloss', \n",
    "                eval_set=evals, verbose=True)\n",
    "\n",
    "preds = xgb_wrapper.predict(X_test)\n",
    "pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, preds, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "363ef454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.585235</td>\n",
       "      <td>0.033688</td>\n",
       "      <td>-0.947296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.727186</td>\n",
       "      <td>0.105956</td>\n",
       "      <td>-0.960483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.959945</td>\n",
       "      <td>0.154804</td>\n",
       "      <td>-0.958290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.950012</td>\n",
       "      <td>0.120686</td>\n",
       "      <td>-0.960468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.674336</td>\n",
       "      <td>0.142392</td>\n",
       "      <td>-0.962661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.863774</td>\n",
       "      <td>0.106579</td>\n",
       "      <td>-0.958275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.957521</td>\n",
       "      <td>0.079111</td>\n",
       "      <td>-0.956097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.695018</td>\n",
       "      <td>0.095213</td>\n",
       "      <td>-0.960468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.684442</td>\n",
       "      <td>0.147520</td>\n",
       "      <td>-0.962661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.592116</td>\n",
       "      <td>0.081179</td>\n",
       "      <td>-0.956097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.614798</td>\n",
       "      <td>0.076255</td>\n",
       "      <td>-0.956082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.776738</td>\n",
       "      <td>0.089624</td>\n",
       "      <td>-0.960468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.514772</td>\n",
       "      <td>0.092214</td>\n",
       "      <td>-0.958275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.949783</td>\n",
       "      <td>0.083983</td>\n",
       "      <td>-0.949474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926121</td>\n",
       "      <td>0.112477</td>\n",
       "      <td>-0.949489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.570990</td>\n",
       "      <td>0.064663</td>\n",
       "      <td>-0.958290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.884549</td>\n",
       "      <td>0.042766</td>\n",
       "      <td>-0.949489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.548302</td>\n",
       "      <td>0.184028</td>\n",
       "      <td>-0.962647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.910278</td>\n",
       "      <td>0.133006</td>\n",
       "      <td>-0.960468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.532501</td>\n",
       "      <td>0.091771</td>\n",
       "      <td>-0.964869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644890</td>\n",
       "      <td>0.189043</td>\n",
       "      <td>-0.958275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.780915</td>\n",
       "      <td>0.154057</td>\n",
       "      <td>-0.960468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.510122</td>\n",
       "      <td>0.169793</td>\n",
       "      <td>-0.960483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.822165</td>\n",
       "      <td>0.054728</td>\n",
       "      <td>-0.947296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.647444</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>-0.936316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.542415</td>\n",
       "      <td>0.126014</td>\n",
       "      <td>-0.967062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538160</td>\n",
       "      <td>0.128161</td>\n",
       "      <td>-0.962676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.506463</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>-0.940717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.170540</td>\n",
       "      <td>-0.958275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.564500</td>\n",
       "      <td>0.025787</td>\n",
       "      <td>-0.942924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.733826</td>\n",
       "      <td>0.058339</td>\n",
       "      <td>-0.951696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.501102</td>\n",
       "      <td>0.119548</td>\n",
       "      <td>-0.967062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.597853</td>\n",
       "      <td>0.170319</td>\n",
       "      <td>-0.960454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.501951</td>\n",
       "      <td>0.113862</td>\n",
       "      <td>-0.962676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.709170</td>\n",
       "      <td>0.135741</td>\n",
       "      <td>-0.960454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.999433</td>\n",
       "      <td>0.199366</td>\n",
       "      <td>-0.960454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.651538</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>-0.960454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.839988</td>\n",
       "      <td>0.101882</td>\n",
       "      <td>-0.958275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.765179</td>\n",
       "      <td>0.149996</td>\n",
       "      <td>-0.956053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.613403</td>\n",
       "      <td>0.139308</td>\n",
       "      <td>-0.958290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666513</td>\n",
       "      <td>0.102078</td>\n",
       "      <td>-0.962661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.559546</td>\n",
       "      <td>0.069568</td>\n",
       "      <td>-0.960483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.527415</td>\n",
       "      <td>0.161834</td>\n",
       "      <td>-0.967062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.588290</td>\n",
       "      <td>0.160257</td>\n",
       "      <td>-0.962661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804978</td>\n",
       "      <td>0.116651</td>\n",
       "      <td>-0.951696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.696878</td>\n",
       "      <td>0.145955</td>\n",
       "      <td>-0.964854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.524901</td>\n",
       "      <td>0.181720</td>\n",
       "      <td>-0.964854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.725896</td>\n",
       "      <td>0.198962</td>\n",
       "      <td>-0.964840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630900</td>\n",
       "      <td>0.107408</td>\n",
       "      <td>-0.960497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.675242</td>\n",
       "      <td>0.125260</td>\n",
       "      <td>-0.960468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_child_weight  colsample_bytree  learning_rate    losses\n",
       "0        19.0               2.0          0.585235       0.033688 -0.947296\n",
       "1         5.0               2.0          0.727186       0.105956 -0.960483\n",
       "2         6.0               2.0          0.959945       0.154804 -0.958290\n",
       "3         6.0               2.0          0.950012       0.120686 -0.960468\n",
       "4        16.0               2.0          0.674336       0.142392 -0.962661\n",
       "5         8.0               2.0          0.863774       0.106579 -0.958275\n",
       "6        14.0               2.0          0.957521       0.079111 -0.956097\n",
       "7        19.0               2.0          0.695018       0.095213 -0.960468\n",
       "8         9.0               2.0          0.684442       0.147520 -0.962661\n",
       "9         8.0               1.0          0.592116       0.081179 -0.956097\n",
       "10        6.0               2.0          0.614798       0.076255 -0.956082\n",
       "11        7.0               2.0          0.776738       0.089624 -0.960468\n",
       "12        8.0               2.0          0.514772       0.092214 -0.958275\n",
       "13       19.0               1.0          0.949783       0.083983 -0.949474\n",
       "14       10.0               1.0          0.926121       0.112477 -0.949489\n",
       "15        6.0               2.0          0.570990       0.064663 -0.958290\n",
       "16        7.0               2.0          0.884549       0.042766 -0.949489\n",
       "17       18.0               2.0          0.548302       0.184028 -0.962647\n",
       "18        6.0               2.0          0.910278       0.133006 -0.960468\n",
       "19        9.0               2.0          0.532501       0.091771 -0.964869\n",
       "20       15.0               1.0          0.644890       0.189043 -0.958275\n",
       "21       11.0               1.0          0.780915       0.154057 -0.960468\n",
       "22       11.0               2.0          0.510122       0.169793 -0.960483\n",
       "23       16.0               1.0          0.822165       0.054728 -0.947296\n",
       "24       13.0               2.0          0.647444       0.011072 -0.936316\n",
       "25       17.0               2.0          0.542415       0.126014 -0.967062\n",
       "26       17.0               1.0          0.538160       0.128161 -0.962676\n",
       "27       12.0               2.0          0.506463       0.010147 -0.940717\n",
       "28       13.0               2.0          0.616162       0.170540 -0.958275\n",
       "29       20.0               2.0          0.564500       0.025787 -0.942924\n",
       "30       10.0               2.0          0.733826       0.058339 -0.951696\n",
       "31       14.0               2.0          0.501102       0.119548 -0.967062\n",
       "32       15.0               2.0          0.597853       0.170319 -0.960454\n",
       "33       17.0               1.0          0.501951       0.113862 -0.962676\n",
       "34       14.0               2.0          0.709170       0.135741 -0.960454\n",
       "35       18.0               2.0          0.999433       0.199366 -0.960454\n",
       "36       15.0               2.0          0.651538       0.122986 -0.960454\n",
       "37       20.0               2.0          0.839988       0.101882 -0.958275\n",
       "38       16.0               2.0          0.765179       0.149996 -0.956053\n",
       "39       14.0               1.0          0.613403       0.139308 -0.958290\n",
       "40       17.0               2.0          0.666513       0.102078 -0.962661\n",
       "41       18.0               2.0          0.559546       0.069568 -0.960483\n",
       "42       12.0               2.0          0.527415       0.161834 -0.967062\n",
       "43       12.0               2.0          0.588290       0.160257 -0.962661\n",
       "44       19.0               1.0          0.804978       0.116651 -0.951696\n",
       "45       13.0               2.0          0.696878       0.145955 -0.964854\n",
       "46       11.0               2.0          0.524901       0.181720 -0.964854\n",
       "47       10.0               2.0          0.725896       0.198962 -0.964840\n",
       "48       12.0               1.0          0.630900       0.107408 -0.960497\n",
       "49       14.0               2.0          0.675242       0.125260 -0.960468"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = [loss_dict['loss'] for loss_dict in trial_val.results]\n",
    "result_df = pd.DataFrame({'max_depth': trial_val.vals['max_depth'],\n",
    "                          'min_child_weight': trial_val.vals['min_child_weight'],\n",
    "                          'colsample_bytree': trial_val.vals['colsample_bytree'],\n",
    "                          'learning_rate': trial_val.vals['learning_rate'],\n",
    "                          'losses': losses\n",
    "                         }\n",
    "                        )\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013114eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
